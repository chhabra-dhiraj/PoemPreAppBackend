# -*- coding: utf-8 -*-
"""poem.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zYkIOfC0Zl7DT-aioNP8yP5jHyCUz5fG
"""
import json
import sys
import pandas as pd
import numpy as np
import math

data = pd.read_csv(r'public/poems.csv')

genre = ["all","myth","nature","love"]
genre_class = []
for i in range(0,4):
    genre_class.append([])

n = len(data)

for i in range(0,n):
    genre_class[0].append(i)
    if (data.iloc[i][4] == "Nature"):
        genre_class[2].append(i)
    elif (data.iloc[i][4] == "Love"):
        genre_class[3].append(i)
    else:
        genre_class[1].append(i)

from collections import Counter
import string

import nltk
nltk.download('punkt')

poems = data[:]['content'].str.lower()
poems = poems.values.tolist()

index_sentences_dic = {}

def tokenizePoems(poems):
    for i in range(0,n):
        poem_sentences = nltk.tokenize.sent_tokenize(poems[i])
        index_sentences_dic[i] = poem_sentences

tokenizePoems(poems)

nltk.download('stopwords')
stopwords = nltk.corpus.stopwords.words('english')

punctuation = string.punctuation # !"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~
# Add numbers
punctuation += '0123456789'
# print(punctuation)

sentence_words_dic = {}

def filter_words(sentence_words):
    valids = []
    for word in sentence_words:
        if word not in stopwords and word not in punctuation and len(word)>2:
            valids.append(word)
    return valids

def tokenize_and_filter_sentences(sentence):
    sentence_words = nltk.tokenize.wordpunct_tokenize(sentence)
    sentence_filtered_words = filter_words(sentence_words)
    sentence_words_dic[sentence] = sentence_filtered_words

for poem_index in index_sentences_dic:
        for sentence in index_sentences_dic[poem_index]:
            tokenize_and_filter_sentences(sentence)

key = sys.argv[1]
genr = sys.argv[2].lower()
if genr not in genre:
    gen=0
else:
    gen=genre.index(genr.lower())

matched_sentences = []
for i in range(0,n):
    if i in genre_class[gen]:
        for sentence in index_sentences_dic[i]:
            if sentence in index_sentences_dic[i]:
                for word in sentence_words_dic[sentence]:
                    if word == key:
                        author = data.iloc[i][0]
                        name = data.iloc[i][2]
                        age = data.iloc[i][3]
                        matched_sentences.append({
                            "author": author,
                            "poemName": name,
                            "age": age,
                            "sentence": sentence
                        })

results = {
    "isSuccessful": True,
"message": "Successfully searched poems",
"sentencesList": matched_sentences
}
# results["isSuccesfull"] = True
# results["message"] = "Successfully searched poems"
# results["sentencesList"] = matched_sentences
json_data=json.dumps(results)
print(json_data)